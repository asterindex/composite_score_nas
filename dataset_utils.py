"""
–£—Ç–∏–ª—ñ—Ç–∏ –¥–ª—è —Ä–æ–±–æ—Ç–∏ –∑ VisDrone –¥–∞—Ç–∞—Å–µ—Ç–æ–º
–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –∞–Ω–æ—Ç–∞—Ü—ñ–π, –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è, —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
"""

import json
from pathlib import Path
from typing import Dict, List, Tuple
from collections import Counter

import numpy as np
from PIL import Image, ImageDraw
import matplotlib.pyplot as plt


# VisDrone –∫–ª–∞—Å–∏
VISDRONE_CLASSES = {
    0: 'ignored',
    1: 'pedestrian',
    2: 'people',
    3: 'bicycle',
    4: 'car',
    5: 'van',
    6: 'truck',
    7: 'tricycle',
    8: 'awning-tricycle',
    9: 'bus',
    10: 'motor'
}


def parse_annotation(ann_path: Path) -> List[Dict]:
    """
    –ü–∞—Ä—Å–∏–Ω–≥ –∞–Ω–æ—Ç–∞—Ü—ñ—ó VisDrone
    
    –§–æ—Ä–º–∞—Ç: <bbox_left>,<bbox_top>,<bbox_width>,<bbox_height>,<score>,<object_category>,<truncation>,<occlusion>
    """
    annotations = []
    
    with open(ann_path, 'r') as f:
        for line in f:
            parts = line.strip().split(',')
            if len(parts) >= 8:
                x, y, w, h = map(int, parts[:4])
                score = int(parts[4])
                category = int(parts[5])
                truncation = int(parts[6])
                occlusion = int(parts[7])
                
                if score > 0 and 1 <= category <= 10:  # –í–∞–ª—ñ–¥–Ω—ñ –æ–±'—î–∫—Ç–∏
                    annotations.append({
                        'bbox': [x, y, x+w, y+h],
                        'category': category,
                        'class_name': VISDRONE_CLASSES[category],
                        'score': score,
                        'truncation': truncation,
                        'occlusion': occlusion
                    })
    
    return annotations


def visualize_sample(image_path: Path, ann_path: Path, output_path: Path = None):
    """–í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑ bounding boxes"""
    
    image = Image.open(image_path).convert('RGB')
    draw = ImageDraw.Draw(image)
    
    annotations = parse_annotation(ann_path)
    
    for ann in annotations:
        bbox = ann['bbox']
        label = ann['class_name']
        
        # Draw box
        draw.rectangle(bbox, outline='red', width=2)
        
        # Draw label
        draw.text((bbox[0], bbox[1]-10), label, fill='red')
    
    if output_path:
        image.save(output_path)
    else:
        plt.figure(figsize=(12, 8))
        plt.imshow(image)
        plt.axis('off')
        plt.show()


def dataset_statistics(data_root: Path, split: str = 'train') -> Dict:
    """
    –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç—É
    
    Returns:
        Dict –∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ—é: –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∑–æ–±—Ä–∞–∂–µ–Ω—å, –æ–±'—î–∫—Ç—ñ–≤, —Ä–æ–∑–ø–æ–¥—ñ–ª –∫–ª–∞—Å—ñ–≤ —Ç–æ—â–æ
    """
    
    images_dir = data_root / split / 'images'
    annotations_dir = data_root / split / 'annotations'
    
    image_files = list(images_dir.glob('*.jpg'))
    
    stats = {
        'split': split,
        'n_images': len(image_files),
        'class_distribution': Counter(),
        'objects_per_image': [],
        'image_sizes': []
    }
    
    for img_path in image_files:
        # Image size
        with Image.open(img_path) as img:
            stats['image_sizes'].append(img.size)
        
        # Annotations
        ann_path = annotations_dir / img_path.with_suffix('.txt').name
        if ann_path.exists():
            annotations = parse_annotation(ann_path)
            stats['objects_per_image'].append(len(annotations))
            
            for ann in annotations:
                stats['class_distribution'][ann['class_name']] += 1
    
    # –û–±—á–∏—Å–ª–µ–Ω–Ω—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    stats['avg_objects_per_image'] = np.mean(stats['objects_per_image']) if stats['objects_per_image'] else 0
    stats['total_objects'] = sum(stats['class_distribution'].values())
    
    return stats


def print_statistics(stats: Dict):
    """–í–∏–≤–µ–¥–µ–Ω–Ω—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç—É"""
    
    print(f"\n{'='*60}")
    print(f"VisDrone Dataset Statistics: {stats['split']}")
    print(f"{'='*60}")
    print(f"üì∏ –ó–æ–±—Ä–∞–∂–µ–Ω—å: {stats['n_images']}")
    print(f"üì¶ –û–±'—î–∫—Ç—ñ–≤: {stats['total_objects']}")
    print(f"üìä –°–µ—Ä–µ–¥–Ω—è –∫—ñ–ª—å–∫—ñ—Å—Ç—å –æ–±'—î–∫—Ç—ñ–≤ –Ω–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è: {stats['avg_objects_per_image']:.2f}")
    
    print(f"\nüè∑Ô∏è  –†–æ–∑–ø–æ–¥—ñ–ª –∫–ª–∞—Å—ñ–≤:")
    for class_name, count in stats['class_distribution'].most_common():
        percentage = (count / stats['total_objects']) * 100
        print(f"   {class_name:20s}: {count:6d} ({percentage:5.2f}%)")


if __name__ == '__main__':
    # –ü—Ä–∏–∫–ª–∞–¥ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
    data_root = Path('data')
    
    # Train statistics
    train_stats = dataset_statistics(data_root, 'train')
    print_statistics(train_stats)
    
    # Val statistics
    val_stats = dataset_statistics(data_root, 'val')
    print_statistics(val_stats)
